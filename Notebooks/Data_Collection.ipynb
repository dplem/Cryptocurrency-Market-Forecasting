{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Data Collection from Reddit Cryptocurrency Subreddits\r\n",
    "\r\n",
    "https://medium.com/@pasdan/how-to-scrap-reddit-using-pushshift-io-via-python-a3ebcc9b83f4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import math\r\n",
    "import json\r\n",
    "import requests\r\n",
    "import itertools\r\n",
    "import numpy as np\r\n",
    "import time\r\n",
    "from datetime import datetime, timedelta\r\n",
    "import praw"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def make_request(uri, max_retries = 5):\r\n",
    "    def fire_away(uri):\r\n",
    "        response = requests.get(uri)\r\n",
    "        assert response.status_code == 200\r\n",
    "        return json.loads(response.content)\r\n",
    "    current_tries = 1\r\n",
    "    while current_tries < max_retries:\r\n",
    "        try:\r\n",
    "            time.sleep(1)\r\n",
    "            response = fire_away(uri)\r\n",
    "            return response\r\n",
    "        except:\r\n",
    "            time.sleep(1)\r\n",
    "            current_tries += 1\r\n",
    "    return fire_away(uri)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def pull_posts_for(subreddit, start_at, end_at):\r\n",
    "    \r\n",
    "    def map_posts(posts):\r\n",
    "        return list(map(lambda post: {\r\n",
    "            'id': post['id'],\r\n",
    "            'created_utc': post['created_utc'],\r\n",
    "            'prefix': 't4_'\r\n",
    "        }, posts))\r\n",
    "    \r\n",
    "    SIZE = 500\r\n",
    "    URI_TEMPLATE = r'https://api.pushshift.io/reddit/search/submission?subreddit={}&after={}&before={}&size={}'\r\n",
    "    \r\n",
    "    post_collections = map_posts( \\\r\n",
    "        make_request( \\\r\n",
    "            URI_TEMPLATE.format( \\\r\n",
    "                subreddit, start_at, end_at, SIZE))['data'])\r\n",
    "    n = len(post_collections)\r\n",
    "    while n == SIZE:\r\n",
    "        last = post_collections[-1]\r\n",
    "        new_start_at = last['created_utc'] - (10)\r\n",
    "        \r\n",
    "        more_posts = map_posts( \\\r\n",
    "            make_request( \\\r\n",
    "                URI_TEMPLATE.format( \\\r\n",
    "                    subreddit, new_start_at, end_at, SIZE))['data'])\r\n",
    "        \r\n",
    "        n = len(more_posts)\r\n",
    "        post_collections.extend(more_posts)\r\n",
    "\r\n",
    "    return post_collections"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def give_me_intervals(start_at, number_of_days_per_interval = 3):\r\n",
    "    \r\n",
    "    end_at = math.ceil(datetime.utcnow().timestamp())\r\n",
    "        \r\n",
    "    ## 1 day = 86400,\r\n",
    "    period = (86400 * number_of_days_per_interval)\r\n",
    "    end = start_at + period\r\n",
    "    yield (int(start_at), int(end))\r\n",
    "    padding = 1\r\n",
    "    while end <= end_at:\r\n",
    "        start_at = end + padding\r\n",
    "        end = (start_at - padding) + period\r\n",
    "        yield int(start_at), int(end)\r\n",
    "## test out the solution,\r\n",
    "start_at = math.floor(\\\r\n",
    "     (datetime.utcnow() - timedelta(days=365)).timestamp())\r\n",
    "list(give_me_intervals(start_at, 7))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(1599607893, 1600212693),\n",
       " (1600212694, 1600817493),\n",
       " (1600817494, 1601422293),\n",
       " (1601422294, 1602027093),\n",
       " (1602027094, 1602631893),\n",
       " (1602631894, 1603236693),\n",
       " (1603236694, 1603841493),\n",
       " (1603841494, 1604446293),\n",
       " (1604446294, 1605051093),\n",
       " (1605051094, 1605655893),\n",
       " (1605655894, 1606260693),\n",
       " (1606260694, 1606865493),\n",
       " (1606865494, 1607470293),\n",
       " (1607470294, 1608075093),\n",
       " (1608075094, 1608679893),\n",
       " (1608679894, 1609284693),\n",
       " (1609284694, 1609889493),\n",
       " (1609889494, 1610494293),\n",
       " (1610494294, 1611099093),\n",
       " (1611099094, 1611703893),\n",
       " (1611703894, 1612308693),\n",
       " (1612308694, 1612913493),\n",
       " (1612913494, 1613518293),\n",
       " (1613518294, 1614123093),\n",
       " (1614123094, 1614727893),\n",
       " (1614727894, 1615332693),\n",
       " (1615332694, 1615937493),\n",
       " (1615937494, 1616542293),\n",
       " (1616542294, 1617147093),\n",
       " (1617147094, 1617751893),\n",
       " (1617751894, 1618356693),\n",
       " (1618356694, 1618961493),\n",
       " (1618961494, 1619566293),\n",
       " (1619566294, 1620171093),\n",
       " (1620171094, 1620775893),\n",
       " (1620775894, 1621380693),\n",
       " (1621380694, 1621985493),\n",
       " (1621985494, 1622590293),\n",
       " (1622590294, 1623195093),\n",
       " (1623195094, 1623799893),\n",
       " (1623799894, 1624404693),\n",
       " (1624404694, 1625009493),\n",
       " (1625009494, 1625614293),\n",
       " (1625614294, 1626219093),\n",
       " (1626219094, 1626823893),\n",
       " (1626823894, 1627428693),\n",
       " (1627428694, 1628033493),\n",
       " (1628033494, 1628638293),\n",
       " (1628638294, 1629243093),\n",
       " (1629243094, 1629847893),\n",
       " (1629847894, 1630452693),\n",
       " (1630452694, 1631057493),\n",
       " (1631057494, 1631662293)]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Set Reddit API Credentials\r\n",
    "reddit = praw.Reddit(\r\n",
    "     client_id=\"3gRvZgbUzCz_Tg\",\r\n",
    "     client_secret=\"BuNkAnAhJFZhtDMw303NyxiIonIkpg\",\r\n",
    "     user_agent=\"image-scraper\"\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sub_list = ['Cryptocurrency', 'Altcoin', 'Best_of_Crypto', 'BitcoinMarkets', 'Blockchain', 'CryptoMarkets', \r\n",
    "            'CryptoTechnology', 'CryptoTrade']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for x in sub_list:\r\n",
    "    subreddit = x\r\n",
    "    start_at = math.floor(\\\r\n",
    "    (datetime.utcnow() - timedelta(days=365)).timestamp())\r\n",
    "    posts = []\r\n",
    "    for interval in give_me_intervals(start_at, 7):\r\n",
    "        pulled_posts = pull_posts_for(\r\n",
    "            subreddit, interval[0], interval[1])\r\n",
    "    \r\n",
    "        posts.extend(pulled_posts)\r\n",
    "        time.sleep(.500)\r\n",
    "\r\n",
    "    ## WARNING: REDDIT WILL THROTTLE YOU IF YOU ARE ANNOYING! BE KIND!\r\n",
    "    TIMEOUT_AFTER_COMMENT_IN_SECS = .350\r\n",
    "    posts_from_reddit = []\r\n",
    "    comments_from_reddit = []\r\n",
    "    for submission_id in np.unique([ post['id'] for post in posts ]):\r\n",
    "        submission = reddit.submission(id=submission_id)\r\n",
    "        posts_from_reddit.append(submission)\r\n",
    "        submission.comments.replace_more(limit=None)\r\n",
    "        for comment in submission.comments.list():\r\n",
    "            comments_from_reddit.append(comment)\r\n",
    "        \r\n",
    "            if TIMEOUT_AFTER_COMMENT_IN_SECS > 0:\r\n",
    "                time.sleep(TIMEOUT_AFTER_COMMENT_IN_SECS)\r\n",
    "\r\n",
    "    print(len(posts_from_reddit))\r\n",
    "\r\n",
    "    print(len(comments_from_reddit))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "subreddit = 'Siacoin'\r\n",
    "start_at = math.floor(\\\r\n",
    "    (datetime.utcnow() - timedelta(days=365)).timestamp())\r\n",
    "posts = []\r\n",
    "for interval in give_me_intervals(start_at, 7):\r\n",
    "    pulled_posts = pull_posts_for(\r\n",
    "        subreddit, interval[0], interval[1])\r\n",
    "    \r\n",
    "    posts.extend(pulled_posts)\r\n",
    "    time.sleep(.500)\r\n",
    "## ~ 4306\r\n",
    "print(len(posts))\r\n",
    "## ~ 4306\r\n",
    "print(len(np.unique([ post['id'] for post in posts ])))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2379\n",
      "2379\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "## WARNING: REDDIT WILL THROTTLE YOU IF YOU ARE ANNOYING! BE KIND!\r\n",
    "TIMEOUT_AFTER_COMMENT_IN_SECS = .350\r\n",
    "posts_from_reddit = []\r\n",
    "comments_from_reddit = []\r\n",
    "for submission_id in np.unique([ post['id'] for post in posts ]):\r\n",
    "    submission = reddit.submission(id=submission_id)\r\n",
    "    posts_from_reddit.append(submission)\r\n",
    "    submission.comments.replace_more(limit=None)\r\n",
    "    for comment in submission.comments.list():\r\n",
    "        comments_from_reddit.append(comment)\r\n",
    "        \r\n",
    "        if TIMEOUT_AFTER_COMMENT_IN_SECS > 0:\r\n",
    "            time.sleep(TIMEOUT_AFTER_COMMENT_IN_SECS)\r\n",
    "## ~ 4306\r\n",
    "print(len(posts_from_reddit))\r\n",
    "## ~ 35216\r\n",
    "print(len(comments_from_reddit))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for x in sub_list:\r\n",
    "\r\n",
    "    # Define name of subreddit\r\n",
    "    sub = x\r\n",
    "    # Define the name of the directory to be created. Replace with your directory location.\r\n",
    "    csv_dir = '../Data/Top/'\r\n",
    "\r\n",
    "    # Define directory for parquet file.\r\n",
    "    parquet_dir = '../Data/Parquet/'\r\n",
    "    \r\n",
    "    # Sort Submissions by: rising, new, hot, gilded, controversial, top\r\n",
    "    # Replace 'top' with any of the sorting options from above\r\n",
    "    # Max limit of 1000 requests\r\n",
    "    # Estimated time of 9 minutes to run this cell\r\n",
    "\r\n",
    "    d = []\r\n",
    "\r\n",
    "    for submission in reddit.subreddit(sub).top(limit=None):\r\n",
    "        d.append(                                            \r\n",
    "            {                                                \r\n",
    "                'Title': submission.title,\r\n",
    "                'Score': submission.score,\r\n",
    "                'Id':  submission.id,\r\n",
    "                #'Url': submission.url,\r\n",
    "                #'Author': submission.author,\r\n",
    "                'Comments': submission.comments,\r\n",
    "                'Created_utc': submission.created_utc,\r\n",
    "                #'Original Content': submission.is_original_content,\r\n",
    "                #'Flair Text': submission.link_flair_text,\r\n",
    "                #'Full Name': submission.name,\r\n",
    "                #'Locked': submission.locked,\r\n",
    "                'Number of Comments': submission.num_comments,\r\n",
    "                #'NSFW': submission.over_18,\r\n",
    "                'Upvote Percentage': submission.upvote_ratio,\r\n",
    "                'Text': submission.selftext\r\n",
    "            }\r\n",
    "        )\r\n",
    "\r\n",
    "    df = pd.DataFrame(d)\r\n",
    "    \r\n",
    "    # Create date string for csv file name\r\n",
    "    timestr = time.strftime(\"%Y%m%d\")\r\n",
    "    \r\n",
    "    # Save dataframe to csv file\r\n",
    "    df.to_csv(csv_dir + sub + '_' + timestr + '.csv', index = False)\r\n",
    "\r\n",
    "    # Save to parquet file\r\n",
    "    #df.to_parquet(parquet_dir + sub + '_' + timestr + '.parquet', engine='fastparquet')\r\n",
    "\r\n",
    "    # Sleep 10 seconds to interrupt api connection\r\n",
    "    sleep(10)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "825893eda577408078809c25d9ed95f592e592429a99ce56af90a73b72386c66"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}